
export const NS_OS_000_CHARTER = `**NS OS — Philosophy**

## 1. Why NS OS Exists

NS OS exists because modern operating systems were built for a world that no longer exists.

They assume:

- deterministic execution
- human-issued commands
- static files
- opaque computation
- after-the-fact intelligence

But the world now runs on:

- uncertainty
- probabilistic outcomes
- heterogeneous compute
- continuous optimization
- systems that act, not just respond

NS OS is not an upgrade to existing operating systems. It is a re-grounding of what an operating system is.

## 2. The Core Belief

Computation is no longer just about correctness. It is about navigating uncertainty responsibly.

Deterministic execution remains essential — but insufficient.

NS OS treats:

- uncertainty as a first-class concept
- probability as a native property
- optimization as an ongoing process
- context as durable, not ephemeral

## 3. Intelligence Is Not an Application

NS OS rejects the idea that “intelligence” is something bolted on at the application layer.

Intelligence, in NS OS, is:

- structural
- governed
- auditable
- bounded

This means:

- no hidden agents
- no opaque background actions
- no intelligence without provenance

If the system cannot explain why something happened, it does not count as intelligence.

## 4. Heterogeneous Compute Is the Default

NS OS assumes from first principles that computation will span:

- Deterministic control (CPU)
- Parallel numeric processing (GPU and accelerators)
- Probabilistic, thermodynamic sampling (TSUs and equivalents)

Each class of compute exists for a different purpose.

NS OS does not force one paradigm to imitate another. It routes problems to the kind of physics best suited to solve them.

## 5. Thermodynamic Sampling Is About Humility

Thermodynamic Sampling Units are not “thinking machines.”

They are an admission that:

- some problems are too complex to solve directly
- equilibrium is often more meaningful than precision
- exploration matters as much as optimization

NS OS uses sampling to:

- explore solution spaces
- estimate distributions
- minimize energy under constraints
- reason under uncertainty

Sampling is always bounded, declared, and observable.

## 6. Intent Is a First-Class Primitive

Traditional operating systems execute commands.

NS OS executes intent.

Intent is:

- a declared outcome
- with constraints
- under uncertainty
- subject to policy

This does not remove human agency — it amplifies it.

The system never decides *why* something should happen. It only helps decide *how*, *when*, and with *what tradeoffs*.

## 7. Provenance Is Non-Negotiable

Every meaningful action in NS OS has:

- an origin
- a justification
- a transformation history

Nothing important is allowed to be:

- anonymous
- unexplained
- irreproducible

This is not for surveillance. It is for trust, continuity, and accountability.

A system without provenance eventually becomes dangerous — even to its creators.

## 8. Fields Over Files

Files are an implementation detail.

NS OS treats the world as fields:

- continuous functions over space, time, or state
- derived from raw data
- governed, versioned, and composable

Files still exist — but they are no longer the highest abstraction.

This allows:

- maps instead of tables
- gradients instead of flags
- signals instead of snapshots

## 9. Governance Is a System Property

NS OS assumes that:

- power emerges naturally from computation
- optimization without constraint becomes exploitation
- scale amplifies mistakes faster than wisdom

Therefore:

- governance is built into the OS
- permissions are semantic, not just technical
- capabilities are scoped, revocable, and auditable

The system is designed to fail safely, not silently.

## 10. Continuity Over Sessions

Most operating systems forget everything between reboots.

NS OS treats continuity as fundamental:

- work has memory
- decisions have lineage
- context persists across time

This does not mean omniscience. It means respect for past effort.

A system that forgets too easily wastes human life.

## 11. Substitution Over Dependence

NS OS is designed to survive hardware shifts.

It does not depend on:

- TSUs being widely available
- any single accelerator
- a specific vendor or architecture

Everything works:

- on CPU alone
- better on GPU
- best with thermodynamic sampling

The abstractions come first. The hardware follows.

## 12. Calm Is a Design Goal

NS OS does not aim to:

- overwhelm
- automate recklessly
- maximize activity

It aims to:

- reduce unnecessary cognitive load
- surface tradeoffs clearly
- allow deliberate action

Speed without clarity is not progress.

## 13. What NS OS Refuses to Become

NS OS explicitly rejects:

- hidden autonomous agents
- unbounded optimization
- intelligence without consent
- performance at the cost of legibility

Power without understanding is not intelligence — it is entropy.

## 14. The Long View

NS OS is not designed for:

- the next release cycle
- the next funding round
- the next hype wave

It is designed for:

- decades of evolution
- unknown hardware
- increasing system complexity
- human trust over time

The goal is not to predict the future —
but to remain coherent as the future arrives.

**Closing Statement**

NS OS is an operating system for a world where uncertainty is real, power is subtle, and responsibility matters.

It does not promise certainty. It promises structure, humility, and continuity in the face of complexity.`;

export const NS_OS_001_NON_GOALS = `**NS OS — Prospectus**

## Non-Goals & Explicit Refusals

**Purpose**

This document defines what NS OS explicitly does not aim to be, solve, or optimize for.

In a long-horizon system, clarity of refusal is as important as clarity of intent. These non-goals are not temporary constraints — they are structural boundaries designed to preserve coherence over decades.

## 1. NS OS Is Not a Consumer Operating System

NS OS does not aim to:

- replace desktop or mobile operating systems
- compete for consumer market share
- optimize for entertainment, personalization, or mass usability

NS OS is not designed for casual use. It is designed for serious, long-lived work under uncertainty.

## 2. NS OS Is Not an "AI OS"

NS OS explicitly rejects the framing of being an "AI-first" or "AI-native" operating system.

It does not:

- embed opaque autonomous agents
- prioritize generative output over legibility
- treat intelligence as a magical capability layer

Any intelligence in NS OS must be:

- bounded
- explainable
- governed
- attributable

If a result cannot be traced back to declared intent, constraints, and computation, it is considered invalid.

## 3. NS OS Does Not Promise Optimality

NS OS does not promise:

- globally optimal solutions
- perfect predictions
- maximum efficiency at all times

Instead, NS OS prioritizes:

- robustness over optimality
- explainability over performance
- stability over novelty

Optimization without understanding is treated as a failure mode, not a success metric.

## 4. NS OS Is Not Hardware-Bound

NS OS does not:

- depend on the availability of TSUs
- require specialized accelerators to function
- tie its identity to any vendor or architecture

While NS OS is designed to benefit from heterogeneous compute, all abstractions must remain valid in their absence.

Hardware is a substrate — never the definition.

## 5. NS OS Does Not Centralize Power Invisibly

NS OS explicitly refuses:

- hidden automation
- background decision-making without disclosure
- silent policy enforcement

Any exercise of power within the system must be:

- visible
- attributable
- reversible

The system must never know more than it can justify knowing.

## 6. NS OS Is Not a Surveillance Platform

NS OS does not:

- collect data by default
- retain information without declared purpose
- treat provenance as a mechanism for monitoring people

Provenance exists to explain systems, not to police users.

Memory without restraint is not intelligence — it is accumulation.

## 7. NS OS Does Not Replace Human Judgment

NS OS refuses the goal of removing humans from decision-making loops.

It does not:

- act autonomously without consent
- finalize decisions without review
- substitute optimization for responsibility

The system may surface options, tradeoffs, and probabilities — but accountability always remains human.

## 8. NS OS Is Not a Universal Solution

NS OS does not attempt to:

- solve every class of problem
- unify all computation under a single paradigm
- erase the need for specialized systems

Some problems are better solved elsewhere. NS OS is designed to integrate — not dominate.

## 9. NS OS Does Not Optimize for Speed Alone

NS OS explicitly deprioritizes:

- raw throughput as a primary goal
- constant activity
- speed without comprehension

Latency is acceptable when it produces clarity.

## 10. NS OS Refuses Premature Commitment

During the Prospectus and Conception phases, NS OS will not:

- lock APIs
- promise compatibility
- declare timelines
- accept external dependencies

Stability is earned through understanding, not announcement.

**Closing Note**

These non-goals are not limitations.

They are load-bearing constraints that protect NS OS from becoming:

- incoherent
- extractive
- ungovernable
- or misaligned with its founding philosophy

Anything that violates these refusals is, by definition, not NS OS — regardless of how impressive it may appear.`;

export const NS_OS_002_PRIMITIVES = `**NS OS — Prospectus**

## Core Primitives

**Purpose**

This document defines the conceptual primitives of NS OS.

These primitives are not APIs, data structures, or implementation details. They are the irreducible ideas from which all future system design, architecture, and behavior must be derived.

If a concept cannot be expressed using these primitives, it does not belong in NS OS.

## 1. Intent

Intent is a declared desired outcome, expressed with constraints and tolerance for uncertainty.

Intent is:

- outcome-oriented, not procedural
- bounded by policy and context
- evaluated over time, not at a single instant

Intent does not specify how something must be done — only what must be achieved and under what conditions.

In NS OS, execution exists to serve intent, not the reverse.

## 2. Constraint

A Constraint is a non-negotiable boundary within which intent must be satisfied.

Constraints may include:

- resource limits
- policy rules
- ethical or governance requirements
- temporal or spatial bounds

Constraints are not failures of optimization. They are the structure that gives optimization meaning.

## 3. Uncertainty

Uncertainty represents what the system does not and cannot know deterministically.

NS OS treats uncertainty as:

- explicit
- measurable
- unavoidable

Rather than hiding uncertainty behind false precision, NS OS surfaces it as a first-class property of computation.

Uncertainty is not an error state. It is the normal operating condition of complex systems.

## 4. Field

A Field is a governed, versioned function over space, time, or state.

Fields:

- may be continuous or discrete
- may be derived or primitive
- always declare provenance

Fields replace static snapshots with living representations of reality.

Files may store fields, but fields are not files.

## 5. Provenance

Provenance is the complete lineage of how a result came to exist.

It includes:

- source origins
- transformations applied
- assumptions made
- constraints enforced

Provenance is required for trust, continuity, and accountability.

Without provenance, results are considered incomplete — regardless of accuracy.

## 6. Policy

Policy encodes what is permitted, forbidden, or required within the system.

Policy is:

- declarative
- enforceable
- inspectable
- revisable

Policy governs both human and non-human actors equally.

Optimization that violates policy is treated as invalid by definition.

## 7. Capability

A Capability is an explicitly granted scope of action.

Capabilities:

- are narrow by default
- may be revoked
- are auditable
- never implied

Possession of a capability is required to act.

Authority without capability does not exist in NS OS.

## 8. State

State represents the current condition of the system relative to declared intent.

State is:

- contextual
- versioned
- persistent across sessions

State exists to preserve continuity, not to accumulate history indiscriminately.

## 9. Continuity

Continuity is the principle that meaningful work should not be lost to time or interruption.

Continuity ensures:

- decisions have memory
- progress is preserved
- context survives across sessions

Continuity is distinct from surveillance. It exists to respect effort, not to monitor behavior.

## 10. Execution

Execution is the act of applying compute to advance intent under constraints and uncertainty.

Execution may be:

- deterministic
- parallel
- probabilistic

Execution is never autonomous in purpose. It is always subordinate to declared intent and policy.

**Closing Statement**

These primitives are intentionally minimal.

They are designed to:

- remain stable over decades
- survive hardware transitions
- prevent conceptual drift

Any future feature, subsystem, or abstraction must be expressible as a composition of these primitives — or it does not belong in NS OS.`;

export const NS_OS_003_WORLDVIEW = `**NS OS — Prospectus**

## Compute Worldview

**Purpose**

This document defines how NS OS understands computation itself.

It does not specify architectures, vendors, or implementations. It establishes a worldview: a principled way of matching problems to the physical realities best suited to address them.

NS OS treats computation as heterogeneous by default.

## 1. Computation Is Not Monolithic

Traditional operating systems implicitly assume a single dominant mode of computation: deterministic instruction execution.

NS OS rejects this assumption.

Modern problems span multiple computational realities, each governed by different constraints and strengths. Treating them as interchangeable leads to inefficiency, opacity, and failure.

NS OS assumes that different kinds of problems require different kinds of physics.

## 2. Deterministic Compute (Control Plane)

Deterministic compute exists to:

- enforce policy
- manage resources
- preserve correctness
- guarantee repeatability

This mode of computation is:

- precise
- auditable
- predictable

In NS OS, deterministic compute forms the control plane. It is responsible for maintaining system integrity, boundaries, and trust.

Determinism is not abandoned — it is protected.

## 3. Parallel Numeric Compute (Acceleration Plane)

Some problems are best solved through massive parallelism.

Parallel numeric compute exists to:

- process large data volumes
- evaluate vectorized operations
- simulate complex systems
- accelerate statistical computation

This mode of computation values throughput over strict ordering.

In NS OS, parallel compute forms the acceleration plane. It is used when scale and speed matter more than step-by-step traceability.

Acceleration must always remain subordinate to control.

## 4. Probabilistic Sampling Compute (Thermodynamic Plane)

Certain problems resist deterministic solution entirely.

These include:

- optimization under uncertainty
- exploration of large solution spaces
- equilibrium discovery
- probabilistic inference

For these problems, sampling is not an approximation — it is the correct approach.

NS OS recognizes probabilistic sampling compute as a distinct computational plane.

This plane is grounded in physical processes that naturally explore energy landscapes rather than exhaustively enumerating possibilities.

## 5. Thermodynamic Sampling as a First-Class Capability

Thermodynamic sampling is not treated as intelligence.

It is treated as:

- a method of exploration
- a way to estimate distributions
- a mechanism for finding stable configurations

Sampling is always:

- bounded
- declared
- observable
- subordinate to policy

NS OS never allows sampling to silently decide outcomes.

## 6. Routing Problems to Physics

NS OS does not attempt to force all problems into a single computational paradigm.

Instead, it routes work based on:

- intent
- constraints
- uncertainty
- required guarantees

Deterministic control governs.
Parallel acceleration scales.
Probabilistic sampling explores.

This separation preserves clarity and prevents misuse of powerful tools.

## 7. Composition Over Substitution

The compute planes in NS OS are not competitors.

They are composable.

A single intent may involve:

- deterministic policy evaluation
- parallel numerical analysis
- bounded probabilistic sampling

Each plane contributes what it does best.

No plane is allowed to impersonate another.

## 8. Hardware Independence by Design

NS OS does not bind its worldview to specific hardware implementations.

The compute planes are conceptual.

They may be realized through:

- general-purpose processors
- specialized accelerators
- future hardware not yet conceived

The abstractions must remain valid regardless of substrate.

## 9. Why This Worldview Matters

When computational modes are confused:

- optimization becomes ungovernable
- intelligence becomes opaque
- trust erodes

By respecting the limits and strengths of each mode, NS OS maintains:

- legibility
- accountability
- robustness

Power is only useful when it is understood.

**Closing Statement**

NS OS treats computation as a pluralistic discipline.

It does not ask what is fastest, but what is appropriate.

By aligning problems with the physics best suited to address them, NS OS remains coherent in the face of increasing complexity — regardless of how the underlying hardware evolves.`;

// --- SIMULATION / TECHNICAL PROSPECTUS ---

export const PROSPECTUS_000_README = `# NS CPU/GPU/TSU Hybrid OS — Doc Pack

Generated: 2025-12-29 (America/Denver)

This pack proposes an **OS-level compute substrate** for a **CPU + GPU + TSU (Extropic thermodynamic sampling unit)** hybrid.
It treats **probabilistic computation as a first-class primitive** (sampling, conditioning, uncertainty) and exposes a **clean,
stable integration surface** so your existing Northfield Solidarity engines can adopt TSU acceleration without being rewritten.

> Design intent: make “sampling” as normal as “matmul,” while keeping determinism/auditability where it matters.

## Contents
- **001_Vision_and_Principles.md** — goals, non-goals, and design principles
- **002_Probabilistic_Primitives_and_ABI.md** — the core probabilistic primitives (portable across CPU/GPU/TSU)
- **003_Heterogeneous_Compute_Graph.md** — a single graph model with deterministic + sampling nodes
- **004_Scheduler_and_QoS.md** — routing rules, QoS, cost model, and fallback strategies
- **005_TSU_Device_Model_and_Backends.md** — TSU as a “sampling accelerator”; simulated + real backends
- **006_PRS_API.md** — Probabilistic Runtime Service interface (the “one surface” engines call)
- **007_Engine_Integration_Map.md** — how PRS maps into GGE/DRE/quickscope/AEGIS/Switchboard/KILN/etc.
- **008_Observability_Audit_Governance.md** — provenance, replayability, conflict handling
- **009_Security_Isolation_Safety.md** — isolation boundaries, approval gates, safe side-effects
- **010_MVP_Roadmap.md** — pragmatic path: simulation-first → TSU backend later
- **011_Glossary.md**
- **012_References.md**

## Background (TSU context)
Extropic describes TSUs as inherently probabilistic hardware designed for probabilistic workloads, alongside a dev platform (XTR-0)
and software (THRML). See **012_References.md** for sources.

## How to use this pack
- Treat this as your “OS spec nucleus.” We can iterate each section into deeper sub-docs (interfaces, storage, UI, policy, etc.).
- The recommended first build is the **Probabilistic Runtime Service (PRS)** with a **GPU simulation backend**, so your engines
adopt the interface immediately and TSU hardware becomes a backend swap later.`;

export const PROSPECTUS_001_VISION = `# 001 — Vision and Principles

## Vision
Build a **heterogeneous compute substrate** that treats **CPU, GPU, and TSU** as first-class peers and exposes
**probabilistic core primitives** as a stable, composable interface. Your existing engines plug into this substrate
to become more efficient at:
- decision-making under uncertainty
- probabilistic search / planning
- posterior sampling / ranking / risk quantification
- generative or denoising-style pipelines where sampling dominates cost

This is not “an OS” in the classical desktop sense. It is an **OS-adjacent runtime + device model + scheduler + API**
layer that can sit under your projects without infecting them with device-specific complexity.

## Goals
1. **One narrow integration surface** for your engines: a single runtime (PRS) that returns distributions/samples + diagnostics.
2. **Portable probabilistic programs**: the same model/spec can run on TSU, or fall back to GPU simulation.
3. **Determinism where it matters**: activation of decisions is policy-driven and auditable, even if sampling is stochastic.
4. **Measured efficiency**: route work based on latency, energy, accuracy targets, and resource availability.
5. **Clean composability**: sampling nodes interleave with GPU/CPU compute graph nodes in one pipeline.

## Non-goals
- Replacing Linux/macOS as a general-purpose OS.
- Making TSU do dense linear algebra (GPU remains best for that).
- Betting the entire platform on TSU availability (must run fully on CPU/GPU today).
- Enforcing one ML framework (adapter layers should exist for PyTorch/JAX/etc., but substrate stays neutral).

## Core design principles
### P1 — “Sampling is a primitive”
GPU-heavy systems often emulate sampling using massive deterministic arithmetic and PRNG. In this substrate, sampling is
a first-class operation with explicit contracts: \`sample()\`, \`condition()\`, \`score()\`, \`diagnostics()\`.

### P2 — “Backend swap, no engine rewrites”
Engines must not contain TSU-specific code paths. Engines call PRS. PRS chooses the backend: TSU, GPU-sim, CPU reference.

### P3 — “Auditability is a product feature”
Every stochastic decision in an automation chain should be explainable in terms of:
- the probabilistic program
- the constraints and evidence used
- the sampler settings (temperature/schedule)
- the diagnostics and confidence outputs
- the policy gates and approvals that promoted a result into action

### P4 — “Probabilistic + deterministic share one graph”
The unit of execution is a single heterogeneous compute graph (HCG) with:
- deterministic nodes (CPU/GPU kernels)
- sampling nodes (TSU or simulated sampler)

### P5 — “QoS-driven routing”
Routing is governed by a cost model: (latency, energy, accuracy, reversibility risk).
Everything has a fallback.

## What makes this uniquely compatible with your NS engines
You already have:
- governance (GGE)
- research/knowledge graph (DRE)
- state/action management (quickscope)
- dependency visibility (AEGIS)
- model routing (Switchboard)

This substrate gives all of them the same thing: **probabilistic compute as a service**, with clean provenance.`;

export const PROSPECTUS_002_PRIMITIVES = `# 002 — Probabilistic Primitives and ABI

This section defines a **portable ABI** that can run on CPU, GPU, or TSU, and that composes cleanly into pipelines.

## Mental model
- CPU/GPU: evaluate functions; compute features; score candidates; run deterministic transforms.
- TSU: efficiently produce samples from target distributions (or energy-based models).

## Core objects

### 1) SState (Stochastic State)
A typed container for random variables and latent state.

Minimal fields:
- \`dtype\` / \`shape\`
- \`domain\` (discrete / continuous / bounded)
- \`constraints\` (hard and soft)
- \`seed_policy\` (reproducibility guarantees; see below)
- \`version\`

### 2) EProgram (Energy / Factor Program)
A target distribution specified as an energy function or factor/hypergraph model.
This is intentionally compatible with “energy-based model” thinking.

EProgram supports:
- factors / potentials
- constraints (hard/soft)
- conditioning (observations)
- temperature and annealing schedules
- compositional operators (sum-product style, factor composition)

### 3) Sampler Contract
A uniform sampling interface:

\`\`\`
sample(
  eprogram,
  sstate_init,
  n_samples,
  schedule,
  constraints,
  conditioning,
  diagnostics_level
) -> (samples, diagnostics, provenance)
\`\`\`

**Diagnostics** should include:
- mixing proxies (autocorrelation estimates, ESS proxies)
- acceptance stats (if backend uses MCMC-like methods)
- entropy / KL proxies (when available)
- constraint violation counts
- runtime cost metrics (latency, energy estimate)

### 4) Conditioning
Conditioning binds evidence into the distribution:
- hard conditioning: clamp variables / fix observed values
- soft conditioning: add penalty terms to energy

### 5) Score / LogProb
A backend-neutral scoring method:

\`\`\`
score(eprogram, samples) -> scores
\`\`\`

### 6) Uncertainty Return Types
Never return only a point estimate if uncertainty matters.
Return:
- samples or a summary distribution
- confidence intervals / quantiles
- entropy / dispersion
- calibration metrics (when feasible)

## Reproducibility and audit
Stochastic compute is not “replayable” like deterministic compute, but it can be **auditable**.

Define a \`SeedPolicy\`:
- \`BestEffortReplay\`: record seeds, schedule, and backend version
- \`DeterministicSim\`: enforce deterministic GPU-sim sampling (debug mode)
- \`HardwareStochastic\`: accept hardware entropy; record provenance for audit

Record provenance:
- backend (TSU/GPU/CPU) + version
- schedule + hyperparameters
- conditioning inputs hashes
- EProgram hash
- any model prompts/config hashes if LLMs generated the EProgram

## Error model (make failures explicit)
Sampling failures must be typed:
- \`ConstraintInfeasible\`
- \`NonConvergence\`
- \`BudgetExceeded\`
- \`BackendUnavailable\`
- \`NumericalInstability\`
- \`PolicyViolation\`

## Composition operators
Provide operators so engines can build complex probabilistic jobs from smaller ones:
- \`compose(E1, E2)\` (combine energies)
- \`condition(E, obs)\`
- \`marginalize(E, vars)\`
- \`map_reduce_samples(...)\` (distributed sampling)
- \`resample(samples, weights)\` (importance sampling support)

## Why ABI-first matters
If you standardize this ABI, you can:
- integrate now with GPU-sim
- adopt TSU later
- keep engine code stable`;

export const PROSPECTUS_003_HCG = `# 003 — Heterogeneous Compute Graph (HCG)

## Overview
All execution is represented as a single **Heterogeneous Compute Graph**, mixing:
- **D-nodes**: deterministic compute (CPU/GPU kernels)
- **S-nodes**: sampling compute (TSU backend or simulated sampler)

This eliminates “two worlds” and keeps orchestration simple.

## Node types

### D-node (Deterministic)
- feature extraction
- energy evaluation
- scoring / ranking
- embedding, transforms, matmul, NN inference
- constraint compilation

### S-node (Sampling)
- sample from EProgram
- conditional sampling
- annealing schedules
- posterior sample generation
- stochastic search steps

## Dataflow
Nodes pass typed tensors and structured objects:
- tensors: features, logits, energies
- structures: EProgram, SState, constraints, conditioning
- metadata: provenance and policy context

## Minimal graph example (ASCII)

\`\`\`
[inputs] -> (D) Build features --------------------+
                 |                                 |
                 v                                 |
            (D) Build EProgram -----------------> (S) Sample on TSU/GPU-sim -> (D) Score -> (D) Select -> [outputs]
                 ^                                 |
                 |                                 v
             (D) Compile constraints <-------- diagnostics/provenance
\`\`\`

## Compiler responsibilities
A “compiler” in this context is a planner that:
- normalizes EPrograms
- chooses factorization strategies
- determines which subgraphs are eligible for TSU acceleration
- inserts diagnostics and checkpoints
- enforces QoS budgets and policy constraints

## Checkpoints and determinism boundaries
- S-nodes emit diagnostics and provenance.
- Promotion to “action” should happen only through deterministic policy gates (e.g., your governance layer).

## Fallbacks
Every S-node must declare:
1. primary backend: TSU
2. fallback: GPU-sim (fast)
3. last resort: CPU reference (slow but correct)

Graph execution never fails “mysteriously”; it degrades.

## Caching
Cache where safe:
- EProgram compilation artifacts
- constraint compilation
- scoring kernels
Do not cache raw samples unless policy allows (could leak sensitive inference results).`;

export const PROSPECTUS_004_SCHEDULER = `# 004 — Scheduler and QoS

## The routing problem
Given a graph with mixed node types, route each node to CPU/GPU/TSU to minimize cost under constraints.

## QoS inputs
- latency budget (p50/p95 targets)
- energy budget (absolute or relative)
- accuracy target (approx tolerance)
- risk class (reversible vs irreversible side effects)
- availability (TSU present? shared? queued?)
- batch size / parallelism

## Cost model (v1)
Define a simple additive cost model:

- \`Cost = wL*Latency + wE*Energy + wA*Error + wR*RiskPenalty\`

Where:
- Latency and Energy can be measured
- Error is estimated (calibration tables per backend)
- RiskPenalty derives from policy (e.g., high for production changes)

## Default routing rules
### Deterministic nodes
- small/branchy control: CPU
- big tensor ops / NN inference: GPU

### Sampling nodes
- if TSU available and node eligible: TSU
- else: GPU-sim
- else: CPU reference

## Eligibility rules for TSU acceleration
A sampling node is TSU-eligible if:
- EProgram uses supported factor types / constraints
- requested schedule is within backend limits
- required conditioning can be compiled to TSU format
- policy allows hardware stochasticity for this stage

## Admission control
Prevent TSU from becoming a bottleneck:
- queue limits + backpressure
- priority classes (interactive vs batch)
- preemption policy for high-priority jobs (if supported)

## Budget enforcement
- hard timeout per node
- early stopping if diagnostics indicate convergence
- degrade diagnostics_level under load (keep core results)

## “Policy gating” integration
Before side effects, enforce:
- review/approval thresholds
- confidence thresholds (e.g., minimum ESS proxy, constraint satisfaction)
- provenance requirements (must include backend, schedule, evidence hashes)

## Observed performance loops
The scheduler should learn:
- track actual latency/energy for each backend and program class
- update routing tables automatically
- detect regressions or drifts

## Failure handling
Typed failures map to actions:
- \`BackendUnavailable\` -> fallback immediately
- \`BudgetExceeded\` -> reduce samples / degrade / fallback
- \`NonConvergence\` -> escalate diagnostics + require human review
- \`ConstraintInfeasible\` -> produce an “infeasible” result with explanation rather than crash`;

export const PROSPECTUS_005_BACKENDS = `# 005 — TSU Device Model and Backends

## TSU as a “Sampling Accelerator”
Treat TSU like a GPU, but with a different primitive:
- GPU primitive: dense arithmetic kernels (matmul, conv)
- TSU primitive: **sample from a programmable distribution / energy model**

This keeps the abstraction honest and the integration clean.

## Real-world TSU dev platform context
Extropic’s XTR-0 platform is described as a system integrating a CPU, FPGA, and sockets for TSU daughterboards to enable
low-latency communication between Extropic chips and a traditional processor. Their THRML software supports simulation
and development of models intended for TSUs. (See References.)

## Device capabilities (capability flags)
Expose TSU capabilities explicitly:
- supported variable domains (binary, discrete k-ary, etc.)
- supported factor types
- max variable count / connectivity
- supported schedules (annealing, fixed temperature)
- I/O bandwidth and latency characteristics
- diagnostics support level

## Device discovery
Runtime enumerates devices:
- CPU
- GPU (CUDA/ROCm/Metal depending on host)
- TSU (via vendor runtime / driver / RPC to attached platform)

## Backend types
### A) TSU Hardware Backend
- compiles EProgram into TSU-compatible representation
- streams conditioning and schedule
- returns samples + diagnostics

### B) GPU Simulation Backend
- executes EProgram sampling using GPU kernels (fast dev/test)
- supports deterministic simulation mode for debugging

### C) CPU Reference Backend
- correctness-focused, slow
- good for tests and small problems

## Portability contract
Your engines never call TSU directly.
They call PRS; PRS chooses backend; backend implements the same sampler contract.

## Calibration and comparability
Because different backends can produce different sampling characteristics, maintain:
- calibration suites per EProgram class
- statistical tests for output sanity (constraint satisfaction, distribution checks)
- regression checks per backend update

## Diagnostics level tiers
- Tier 0: minimal (latency, basic constraint checks)
- Tier 1: default (mixing proxies, ESS proxies, schedule stats)
- Tier 2: deep (autocorr estimates, additional trace logs)

Tier selection is QoS-dependent.`;

export const PROSPECTUS_006_PRS_API = `# 006 — Probabilistic Runtime Service (PRS) API

## Purpose
PRS is the **one narrow integration surface** your engines call.

It provides:
- portable probabilistic compute (sample/condition/score)
- backend routing (TSU vs GPU-sim vs CPU)
- provenance and diagnostics
- policy gating hooks (for GGE)

## Conceptual API (language-neutral)

### Submit a job
\`\`\`
job_id = prs.submit({
  "eprogram": EProgram,
  "init_state": SState,
  "requests": {
    "n_samples": 2048,
    "outputs": ["samples", "quantiles", "entropy", "top_k_modes"],
    "diagnostics_level": 1
  },
  "qos": {
    "latency_ms_p95": 200,
    "energy_budget": "best_effort",
    "accuracy": "approx_ok"
  },
  "policy": {
    "risk_class": "reversible",
    "requires_review": false,
    "min_confidence": 0.7
  },
  "provenance": {
    "caller_engine": "DRE",
    "task_id": "dre.findings.2025-12-29.abc123"
  }
})
\`\`\`

### Get results
\`\`\`
result = prs.get(job_id)
\`\`\`

Returns:
- \`samples\` (optional)
- \`summary\` (quantiles, moments, entropy)
- \`diagnostics\` (mixing proxies, ESS proxies, constraint checks)
- \`provenance\` (backend used, schedule, versions, hashes)
- \`policy_report\` (what gates were applied)

### Stream mode (optional)
For interactive workloads:
- stream partial samples + diagnostics as they arrive
- allow early stop if confidence threshold met

## Result types (recommended)
- \`SampleSet\`
- \`DistributionSummary\`
- \`UncertaintyBundle\`
- \`DecisionRecommendation\` (only when explicitly requested)

## Policy hooks
PRS should support a pluggable policy engine:
- before running: validate job (permissions, evidence requirements)
- before returning as “actionable”: enforce confidence thresholds, require approvals
- after running: attach audit entries and hashes

## Observability hooks
Every job emits:
- metrics (latency, queue time, energy estimate)
- traces (graph node timings)
- structured logs (backend choice reason)

## Versioning
PRS is a contract. Version it carefully:
- additive changes preferred
- deprecate slowly
- keep old ABI adapters available`;

export const PROSPECTUS_007_INTEGRATION = `# 007 — Engine Integration Map (Northfield Solidarity)

This section maps PRS into your existing and planned engines.

## GGE (Governance Graph Engine)
Use PRS for:
- probabilistic risk scoring with uncertainty intervals
- stochastic simulation of policy outcomes (“what if”)
- conflict resolution: sample from competing hypotheses, then apply deterministic policy gates

Key pattern:
- PRS generates distributions
- GGE decides “activation” deterministically (policy + approvals)

## DRE (Deep Research Engine)
Use PRS for:
- probabilistic ranking of leads / claims
- hypothesis generation and sampling under uncertainty
- exploration/exploitation balancing for research queues

Pattern:
- DRE produces candidate hypotheses
- PRS samples/posterior-ranks
- DRE persists results + provenance into the graph

## quickscope (Intervention state management)
Use PRS for:
- stochastic planning / action selection under uncertain state transitions
- sampling rollouts (Monte Carlo style)
- robust control with constraints

Pattern:
- quickscope defines constraints + objectives (EProgram)
- PRS returns action distributions + confidence
- high-impact actions require explicit gate policies

## NS-AEGIS (dependency management + vuln anticipation)
Use PRS for:
- probabilistic vulnerability exposure forecasting
- mitigation plan optimization under uncertain timelines
- “best next action” sampling when multiple mitigations compete

Pattern:
- deterministic dependency graph ingestion (CPU/GPU)
- probabilistic plan generation (PRS)
- deterministic execution gates (review/approve)

## Switchboard (model router)
Use PRS for:
- probabilistic routing decisions (latency/cost/quality tradeoffs)
- uncertainty-aware fallback selection
- exploration of new routes without destabilizing production

Pattern:
- routes become distributions, not single points
- confidence thresholds decide when exploration is allowed

## KILN (training/fine-tuning playground)
Use PRS for:
- sampling-based optimization experiments
- probabilistic model components (EBM-inspired training, diffusion experiments)
- benchmark comparisons of TSU vs GPU-sim

## Rendezvous (attention routing)
Use PRS for:
- stochastic prioritization of threads/topics under budget constraints
- exploration scheduling (don’t starve low-signal topics)

## Quarentine (ETL scrubbing)
PRS is optional here; mostly deterministic.
Possible use:
- probabilistic anomaly detection / uncertain record linkage`;

export const PROSPECTUS_008_AUDIT = `# 008 — Observability, Audit, and Governance

## Provenance: treat it as a first-class artifact
Every PRS job should emit a “provenance capsule”:
- EProgram hash
- constraints hash
- conditioning hash
- backend (TSU/GPU/CPU) + versions
- schedule parameters
- QoS request
- diagnostics summary
- caller identity (engine, user, automation)

## Replay modes
- deterministic-sim replay (debug)
- best-effort replay (recorded schedule + seed policy)
- non-replayable hardware stochastic (still auditable via capsule)

## Governance pattern (high impact actions)
1. PRS produces distributions + diagnostics.
2. Deterministic gate evaluates:
   - confidence thresholds
   - constraint satisfaction
   - policy requirements (review/approval)
3. Only then do you emit an Action.

## Conflict handling
When PRS outputs are uncertain or conflicting:
- represent conflicts explicitly
- require more evidence or human decision
- avoid “silent overwrites”

## Metrics (minimum)
- queue time, runtime, p50/p95 latency
- samples/sec, diagnostics overhead
- fallback rates (TSU→GPU-sim)
- confidence attainment rates
- failure types distribution

## Debugability
Provide:
- “explain backend choice” output
- compare outputs across backends for the same EProgram
- regression harnesses (statistical tests, not bitwise)`;

export const PROSPECTUS_009_SECURITY = `# 009 — Security, Isolation, and Safety

## Isolation boundaries
- Engine code runs in its own process/container boundary.
- PRS runs as a service with strict authentication and authorization.
- Device drivers (GPU/TSU) remain privileged; PRS mediates access.

## AuthZ model
Requests must carry:
- engine identity
- user/automation identity (if applicable)
- policy context (risk class, approvals)

## Data handling
Sampling outputs can leak sensitive info. Enforce:
- least privilege output: summary-only for most callers
- explicit permissions for raw samples
- redaction and aggregation policies

## Side effects and safety
All actions should be:
- idempotent
- recorded (outcome artifacts)
- gated by policy

## Safe defaults
- run in simulation backend by default in dev
- require explicit opt-in for hardware stochasticity in regulated/high-impact workflows
- require review for actions affecting production systems

## Supply chain / driver trust
- pin driver/runtime versions
- record version hashes in provenance capsules
- periodic attestation checks

## Rate limiting / abuse prevention
- protect TSU device access
- per-engine quotas
- per-risk-class budgets`;

export const PROSPECTUS_010_ROADMAP = `# 010 — MVP Roadmap (Simulation-first → TSU backend later)

## Phase 0 — Contract first (1–2 weeks equivalent effort)
Deliverables:
- PRS API skeleton (submit/get)
- EProgram + SState schemas
- GPU-sim backend placeholder (even if naive)
- provenance capsule and metrics baseline

Success criteria:
- at least one engine calls PRS and receives structured outputs + provenance.

## Phase 1 — Pick one “TSU-shaped” workload (2–6 weeks)
Recommended: **AEGIS mitigation planning under uncertainty** or **Switchboard routing under uncertainty**.

Deliverables:
- EProgram templates for the chosen workload
- diagnostics that correlate with “good enough” outcomes
- policy gates in GGE that decide when to act

Success criteria:
- measurable improvement over deterministic heuristics (speed or decision quality), even on GPU-sim.

## Phase 2 — Backend maturity
Deliverables:
- GPU-sim sampler optimized
- calibration + regression tests
- routing cost model with learned estimates

Success criteria:
- stable production-like behavior in simulation.

## Phase 3 — TSU integration (when hardware access exists)
Deliverables:
- TSU device plugin (driver/runtime integration)
- compiler/translator from EProgram → TSU format
- calibration for TSU vs sim outputs

Success criteria:
- backend swap with no engine changes
- documented performance/energy deltas.

## Phase 4 — Scale-out
Deliverables:
- multi-device scheduling (multiple GPUs/TSUs)
- queueing, priorities, preemption policy (if supported)
- multi-tenant governance policies

Success criteria:
- PRS becomes shared substrate for multiple engines.`;

export const PROSPECTUS_011_GLOSSARY = `# 011 — Glossary

- **TSU**: Thermodynamic Sampling Unit — probabilistic hardware designed to efficiently sample from distributions / energy models.
- **PRS**: Probabilistic Runtime Service — the single API surface engines call.
- **EProgram**: Energy/Factor Program — the portable specification of the distribution to sample.
- **SState**: Stochastic State — typed container of random variables and constraints.
- **HCG / Heterogeneous Compute Graph**: execution graph mixing deterministic nodes and sampling nodes.
- **QoS**: Quality of Service; latency/energy/accuracy targets.
- **Provenance Capsule**: structured record describing what ran, where, with what settings, and why.

Notes:
- Naming is flexible; the important thing is the contract surfaces and invariants.`;

export const PROSPECTUS_012_REFERENCES = `# 012 — References

Primary / vendor sources:
- Extropic — Thermodynamic Computing: From Zero to One
  https://extropic.ai/writing/thermodynamic-computing-from-zero-to-one
- Extropic — Inside X0 and XTR-0
  https://extropic.ai/writing/inside-x0-and-xtr-0
- Extropic — Software (THRML)
  https://extropic.ai/software
- Extropic — Hardware (XTR-0)
  https://extropic.ai/hardware

Secondary reporting:
- WIRED — Extropic Aims to Disrupt the Data Center Bonanza (Oct 29, 2025)
  https://www.wired.com/story/extropic-aims-to-disrupt-the-data-center-bonanza/

Note: Secondary sources are included for context; treat vendor sources as the authoritative description of Extropic’s stack.`;

// Aliases for registry compatibility
export const NS_OS_004_VISION = PROSPECTUS_001_VISION;
export const NS_OS_005_ABI = PROSPECTUS_002_PRIMITIVES;
export const NS_OS_006_HCG = PROSPECTUS_003_HCG;
export const NS_OS_007_SCHEDULER = PROSPECTUS_004_SCHEDULER;
export const NS_OS_008_TSU = PROSPECTUS_005_BACKENDS;
export const NS_OS_009_PRS = PROSPECTUS_006_PRS_API;
export const NS_OS_010_INTEGRATION = PROSPECTUS_007_INTEGRATION;
export const NS_OS_011_OBSERVABILITY = PROSPECTUS_008_AUDIT;
export const NS_OS_012_SECURITY = PROSPECTUS_009_SECURITY;
export const NS_OS_013_ROADMAP = PROSPECTUS_010_ROADMAP;
export const NS_OS_014_GLOSSARY = PROSPECTUS_011_GLOSSARY;
export const NS_OS_015_REFERENCES = PROSPECTUS_012_REFERENCES;
